= 3.4 Create a Kafka Consumer

include::_attributes.adoc[]

In the same way we created our REST service, we can create our Kafka consumer application from git.  Then, we'll add our Kafka connection using our secret just like we did before.

== Add an Application from Git

Before you begin, make sure you're in the developer view and in the right project.

image::kafka/dev-view.png[alt text]

image::kafka/select-project.png[alt text, 640]

* From the `+Add` menu, click on the `From Git` tile:

image::kafka/from-git.png[alt text, 800]

== Configure the Application

=== Set the Git Repo

* In the *Git Repo URL* field, enter:

[.lines_space]
[.console-input]
[source,text]
----
https://github.com/blues-man/object-detection-kafka-consumer
----

image::kafka/create-consumer-git.png[alt text, 800]

=== Set the App Name

* By default, our new deployment will be added to the existing application `object-detection` we created during our previous app.  We can leave that as is.  We can change the *Name* to  `object-detection-kafka-consumer` if desired. Leave the default resource as *Deployment*.

image::kafka/create-consumer-general.png[alt text, 800]

=== Remove the Route
The Kafka consumer does not need to be exposed externally and does not serve any information.

* Under *Advanced Options*, uncheck *Create a route to the Application*.

image::kafka/create-consumer-advanced.png[alt text, 800]

=== Resource Limits

We'll have to increase the resource limits for the TensorFlow model.

* Click on *Resource Limits*

image::s2i/create-app-limits2.png[Click resource limits]

* Enter in the following values
** CPU
*** Request: `500 millicores`
*** Limit: `1000 millicores` (or `1 cores`)
** Memory
*** Request: `2200 Mi`
*** Limit: `3000 Mi`

image::s2i/create-app-limits-form.png[Create app limits form, 600]
 

=== Create

* Scroll down and click on *Create*:

image::kafka/create-button.png[alt text]

Your new Kafka consumer should be created and is currently building.  

image::kafka/create-consumer-building.png[alt text, 800]

== Add the Secret to the Kafka Consumer

While the application is building, we can add the secret to the deployment. Then it can connect to the Kafka instance and topic and process messages.

* Navigate to Secrets

* Find and Select the secret with your Kafka connection information.

image::kafka/secret-select.png[alt text, 800]

* Click *Add Secret to workload*

* Select *object-detection-kafka-consumer* deployment as the workload.

* Click *Save*

image::kafka/secret-add-to-consumer.png[alt text, 800]

You'll be redirected to your application.  It will redeploy a new pod to pick up the changes.  You can examine the *Environment* tab to confirm it was added.

== Testing your Streaming Application

Once the application is built and the front-end application and kafka consumer are sending and receiving messages, you can test out your application.

* Navigate to the *Topology* for your project.

* Select your front-end application deployment

* Click on the *Route* at the bottom of the detail page

image::kafka/topology-final.png[alt text, 800]

* Select the video icon on the application.

image::kafka/app-screenshot-2.png[alt text, 360]

Try out your application by using the webcam.  You should see the results of the object detection model and the Kafka consumer should be receiving messages in real-time! Pretty neat!